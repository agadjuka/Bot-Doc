"""
Template Processor Service for automatic field detection and marking in documents.
This service analyzes documents and identifies fields that need to be filled with company data.
"""

import json
import logging
import os
import re
import tempfile
import io
import copy
from typing import Dict, List, Tuple
from io import BytesIO

import google.generativeai as genai
from google.oauth2 import service_account
from docx import Document
from docx.shared import RGBColor
from docx.oxml.shared import qn
import docx2txt
from docx2markdown._docx_to_markdown import docx_to_markdown

from config.prompts import PromptManager

logger = logging.getLogger(__name__)


class TemplateProcessorService:
    """
    Service for processing document templates using simplified analysis strategy.
    Analyzes documents and creates two files: preview for user and smart template for storage.
    """
    
    def __init__(self):
        """
        Initialize the TemplateProcessorService using Google Cloud authentication.
        """
        self.prompt_manager = PromptManager()
        self._initialize_gemini()
        logger.info("TemplateProcessorService initialized successfully")
    
    def _remove_highlighting(self, run):
        """
        Remove yellow highlighting from a run by clearing background color.
        
        Args:
            run: python-docx run object
        """
        try:
            # Remove highlighting by clearing the highlight property
            if hasattr(run, '_element'):
                # Remove w:highlight attribute if it exists
                if run._element.get(qn('w:highlight')):
                    del run._element.attrib[qn('w:highlight')]
                
                # Remove w:shd (shading) attribute if it exists
                if run._element.get(qn('w:shd')):
                    del run._element.attrib[qn('w:shd')]
                
                # Also check for highlighting in the run's properties
                run_props = run._element.find(qn('w:rPr'))
                if run_props is not None:
                    highlight_elem = run_props.find(qn('w:highlight'))
                    if highlight_elem is not None:
                        run_props.remove(highlight_elem)
                    
                    shading_elem = run_props.find(qn('w:shd'))
                    if shading_elem is not None:
                        run_props.remove(shading_elem)
                
                # Additional cleanup for any background color formatting
                # Remove any w:color with background color
                color_elem = run_props.find(qn('w:color')) if run_props is not None else None
                if color_elem is not None:
                    # Check if it's a background color (usually has w:val="auto" or specific color)
                    if color_elem.get(qn('w:val')) in ['auto', 'yellow', 'FFFF00']:
                        run_props.remove(color_elem)
            
            # Also try to remove highlighting using python-docx properties
            if hasattr(run, 'font') and hasattr(run.font, 'highlight_color'):
                try:
                    run.font.highlight_color = None
                except:
                    pass
            
            print(f"‚úÖ [HIGHLIGHT] –£–¥–∞–ª–µ–Ω–∞ –∂–µ–ª—Ç–∞—è –∑–∞–ª–∏–≤–∫–∞ –∏–∑ run: '{run.text[:50]}...'")
            
        except Exception as e:
            print(f"‚ö†Ô∏è [HIGHLIGHT] –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –∑–∞–ª–∏–≤–∫–∏: {e}")
            # –ù–µ –∫—Ä–∏—Ç–∏—á–Ω–æ, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É

    def _initialize_gemini(self):
        """Initialize Google Gemini AI service using Google Cloud authentication"""
        try:
            # Get credentials file path
            credentials_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
            if not credentials_path:
                logger.error("GOOGLE_APPLICATION_CREDENTIALS not set")
                raise ValueError("GOOGLE_APPLICATION_CREDENTIALS is required")
            
            if not os.path.exists(credentials_path):
                logger.error(f"Credentials file not found: {credentials_path}")
                raise FileNotFoundError(f"Credentials file not found: {credentials_path}")
            
            # Load service account credentials
            credentials = service_account.Credentials.from_service_account_file(
                credentials_path,
                scopes=['https://www.googleapis.com/auth/generative-language']
            )
            
            # Configure Gemini API with service account credentials
            genai.configure(credentials=credentials)
            
            # Initialize model (using flash model for better performance)
            self.model = genai.GenerativeModel('gemini-2.5-flash')
            logger.info("Gemini AI service initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize Gemini AI service: {e}")
            raise
    
    def _index_runs_and_build_map(self, doc_object: Document) -> Tuple[str, Dict[str, any]]:
        """
        Create detailed indexing of document at run level for precise analysis.
        
        Args:
            doc_object: python-docx Document object
            
        Returns:
            Tuple of (map_for_gemini, coords_dictionary)
            - map_for_gemini: Text map of document with run IDs for AI analysis
            - coords_dictionary: Python dictionary for quick navigation by run IDs
        """
        try:
            print(f"üîç [INDEX] –ù–∞—á–∏–Ω–∞—é –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ run-–æ–≤...")
            
            # Initialize variables
            map_for_gemini = ""
            coords_dictionary = {}
            run_counter = 0
            
            # Process all paragraphs
            for paragraph in doc_object.paragraphs:
                for run in paragraph.runs:
                    # Generate unique ID for this run
                    run_id = f"run-{run_counter}"
                    
                    # Add run to coordinates dictionary (save direct reference to object)
                    coords_dictionary[run_id] = run
                    
                    # Add run to map for Gemini
                    map_for_gemini += f"[{run_id}]{run.text}"
                    
                    # Increment counter
                    run_counter += 1
                
                # Add newline after each paragraph to preserve structure
                map_for_gemini += "\n"
            
            # Process all tables
            for table in doc_object.tables:
                for row in table.rows:
                    for cell in row.cells:
                        for paragraph in cell.paragraphs:
                            for run in paragraph.runs:
                                # Generate unique ID for this run
                                run_id = f"run-{run_counter}"
                                
                                # Add run to coordinates dictionary
                                coords_dictionary[run_id] = run
                                
                                # Add run to map for Gemini
                                map_for_gemini += f"[{run_id}]{run.text}"
                                
                                # Increment counter
                                run_counter += 1
                            
                            # Add newline after each paragraph in table cells
                            map_for_gemini += "\n"
            
            print(f"‚úÖ [INDEX] –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
            print(f"   - –°–æ–∑–¥–∞–Ω–æ {len(coords_dictionary)} run-–æ–≤")
            print(f"   - –†–∞–∑–º–µ—Ä –∫–∞—Ä—Ç—ã –¥–ª—è Gemini: {len(map_for_gemini)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"   - –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –∫–∞—Ä—Ç—ã: {map_for_gemini[:200]}...")
            
            return map_for_gemini, coords_dictionary
            
        except Exception as e:
            print(f"‚ùå [INDEX] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            logger.error(f"Error indexing document runs: {e}")
            return "", {}
    
    def _sync_docs_with_map(self, doc_object: Document, coords_dictionary: Dict[str, any], modified_map: str) -> Tuple[bytes, bytes]:
        """
        Synchronize documents with the modified map from Gemini.
        This method replaces the old surgical approach with simple text synchronization.
        
        Args:
            doc_object: Original Document object
            coords_dictionary: Dictionary mapping run_id to run objects
            modified_map: Modified text map from Gemini with run markers
            
        Returns:
            Tuple of (preview_bytes, smart_template_bytes)
        """
        try:
            print(f"üîÑ [SYNC] –ù–∞—á–∏–Ω–∞—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∫–∞—Ä—Ç–æ–π...")
            print(f"üîÑ [SYNC] –†–∞–∑–º–µ—Ä –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–∞—Ä—Ç—ã: {len(modified_map)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"üîÑ [SYNC] –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –∫–∞—Ä—Ç—ã: {modified_map[:200]}...")
            
            # Step 1: Create completely independent copies of the original document
            print(f"üìã [SYNC] –°–æ–∑–¥–∞—é –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ –∫–æ–ø–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞...")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –≤ –±–∞–π—Ç—ã –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –∑–∞–Ω–æ–≤–æ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–ø–∏–∏
            original_bytes = BytesIO()
            doc_object.save(original_bytes)
            original_bytes.seek(0)
            
            # –°–æ–∑–¥–∞–µ–º preview –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ –±–∞–π—Ç–æ–≤
            preview_doc = Document(original_bytes)
            original_bytes.seek(0)
            
            # –°–æ–∑–¥–∞–µ–º smart template –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ –±–∞–π—Ç–æ–≤
            smart_template_doc = Document(original_bytes)
            
            print(f"‚úÖ [SYNC] –°–æ–∑–¥–∞–Ω—ã –¥–≤–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ –∫–æ–ø–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
            
            # Step 2: Rebuild coordinates dictionary for both copies
            print(f"üîç [SYNC] –ü–µ—Ä–µ—Å—Ç—Ä–∞–∏–≤–∞—é —Å–ª–æ–≤–∞—Ä–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –¥–ª—è –∫–æ–ø–∏–π...")
            _, preview_coords_dictionary = self._index_runs_and_build_map(preview_doc)
            _, smart_template_coords_dictionary = self._index_runs_and_build_map(smart_template_doc)
            print(f"‚úÖ [SYNC] –°–ª–æ–≤–∞—Ä–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –ø–µ—Ä–µ—Å—Ç—Ä–æ–µ–Ω—ã:")
            print(f"   - Preview: {len(preview_coords_dictionary)} run-–æ–≤")
            print(f"   - Smart template: {len(smart_template_coords_dictionary)} run-–æ–≤")
            
            # Step 3: Parse the modified map to extract run_id and new_text pairs
            print(f"üîç [SYNC] –ü–∞—Ä—Å–∏–Ω–≥ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–∞—Ä—Ç—ã...")
            sync_plan = self._parse_modified_map(modified_map)
            print(f"‚úÖ [SYNC] –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(sync_plan)} –ø–∞—Ä –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏")
            
            # Step 4: Apply synchronization to both documents
            print(f"üîÑ [SYNC] –ü—Ä–∏–º–µ–Ω—è—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º...")
            
            for run_id, new_text in sync_plan.items():
                print(f"üîÑ [SYNC] –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É—é {run_id}: '{new_text[:50]}...'")
                
                # Find target runs in both documents
                preview_run = preview_coords_dictionary.get(run_id)
                smart_template_run = smart_template_coords_dictionary.get(run_id)
                
                if not preview_run:
                    print(f"‚ö†Ô∏è [SYNC] Run {run_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ preview –¥–æ–∫—É–º–µ–Ω—Ç–µ")
                    continue
                    
                if not smart_template_run:
                    print(f"‚ö†Ô∏è [SYNC] Run {run_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ smart template –¥–æ–∫—É–º–µ–Ω—Ç–µ")
                    continue
                
                # Synchronize text in both documents
                preview_run.text = new_text
                smart_template_run.text = new_text
                
                print(f"‚úÖ [SYNC] –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω {run_id}")
            
            print(f"‚úÖ [SYNC] –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            
            # Step 5: Post-processing - Apply styles and placeholders
            print(f"üé® [SYNC] –ü—Ä–∏–º–µ–Ω—è—é —Å—Ç–∏–ª–∏ –∏ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã...")
            
            # Process preview document - apply red bold style to runs with markers
            for run_id, run in preview_coords_dictionary.items():
                if '[' in run.text and ']' in run.text:
                    # Remove highlighting first
                    self._remove_highlighting(run)
                    # Apply red bold style
                    run.font.color.rgb = RGBColor(255, 0, 0)
                    run.bold = True
                    print(f"üé® [SYNC] –ü—Ä–∏–º–µ–Ω–µ–Ω —Å—Ç–∏–ª—å –∫ preview run {run_id}: '{run.text}'")
            
            # Process smart template document - convert markers to placeholders
            for run_id, run in smart_template_coords_dictionary.items():
                if '[' in run.text and ']' in run.text:
                    # Convert [field] to {{field}}
                    new_text = run.text.replace('[', '{{').replace(']', '}}')
                    run.text = new_text
                    print(f"üîß [SYNC] –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä –≤ smart template run {run_id}: '{new_text}'")
            
            print(f"‚úÖ [SYNC] –°—Ç–∏–ª–∏ –∏ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –ø—Ä–∏–º–µ–Ω–µ–Ω—ã")
            
            # Step 6: Save both documents to bytes
            print(f"üíæ [SYNC] –°–æ—Ö—Ä–∞–Ω—è—é –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –±–∞–π—Ç—ã...")
            
            # Save preview document
            preview_stream = BytesIO()
            preview_doc.save(preview_stream)
            preview_bytes = preview_stream.getvalue()
            print(f"‚úÖ [SYNC] Preview –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {len(preview_bytes)} –±–∞–π—Ç")
            
            # Save smart template document
            smart_template_stream = BytesIO()
            smart_template_doc.save(smart_template_stream)
            smart_template_bytes = smart_template_stream.getvalue()
            print(f"‚úÖ [SYNC] Smart template –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {len(smart_template_bytes)} –±–∞–π—Ç")
            
            print(f"üéâ [SYNC] –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            return preview_bytes, smart_template_bytes
            
        except Exception as e:
            print(f"‚ùå [SYNC] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
            logger.error(f"Error in document synchronization: {e}")
            import traceback
            traceback.print_exc()
            return b'', b''
    
    def _parse_modified_map(self, modified_map: str) -> Dict[str, str]:
        """
        Parse the modified map from Gemini to extract run_id and new_text pairs.
        
        Args:
            modified_map: Modified text map with run markers from Gemini
            
        Returns:
            Dictionary mapping run_id to new_text
        """
        try:
            print(f"üîç [PARSE] –ü–∞—Ä—Å–∏–Ω–≥ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–∞—Ä—Ç—ã...")
            
            # Use regex to find all [run-ID]text patterns
            pattern = r'\[(run-\d+)\]([^\[]*)'
            matches = re.findall(pattern, modified_map)
            
            sync_plan = {}
            for run_id, new_text in matches:
                # Clean up the text (remove extra whitespace)
                cleaned_text = new_text.strip()
                sync_plan[run_id] = cleaned_text
                print(f"üîç [PARSE] –ù–∞–π–¥–µ–Ω–∞ –ø–∞—Ä–∞: {run_id} -> '{cleaned_text[:50]}...'")
            
            print(f"‚úÖ [PARSE] –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(sync_plan)} –ø–∞—Ä –∏–∑ –∫–∞—Ä—Ç—ã")
            return sync_plan
            
        except Exception as e:
            print(f"‚ùå [PARSE] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –∫–∞—Ä—Ç—ã: {e}")
            logger.error(f"Error parsing modified map: {e}")
            return {}
    
    async def analyze_and_prepare_templates(self, file_bytes: bytes, file_format: str = '.docx') -> Tuple[bytes, bytes]:
        """
        Analyze document and prepare two files: preview for user and smart template for storage.
        
        Args:
            file_bytes: Document content as bytes
            file_format: File format ('.docx' or '.doc')
            
        Returns:
            Tuple of (preview_bytes, smart_template_bytes)
        """
        try:
            print(f"üìÑ [ANALYZE] –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Ä–∞–∑–º–µ—Ä–æ–º {len(file_bytes)} –±–∞–π—Ç")
            
            # Step 1: Load document using python-docx for precise run-level analysis
            if file_format == '.docx':
                print(f"üìñ [ANALYZE] –ó–∞–≥—Ä—É–∂–∞—é DOCX –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
                doc_object = Document(io.BytesIO(file_bytes))
            elif file_format == '.doc':
                print(f"‚ùå [ANALYZE] DOC —Ñ–æ—Ä–º–∞—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
                return b'', b''
            else:
                print(f"‚ùå [ANALYZE] –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file_format}")
                return b'', b''
            
            # Step 2: Create detailed run-level indexing
            print(f"üîç [ANALYZE] –°–æ–∑–¥–∞—é –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –Ω–∞ —É—Ä–æ–≤–Ω–µ run-–æ–≤...")
            map_for_gemini, coords_dictionary = self._index_runs_and_build_map(doc_object)
            
            if not map_for_gemini.strip():
                print(f"‚ö†Ô∏è [ANALYZE] –î–æ–∫—É–º–µ–Ω—Ç –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å")
                logger.warning("Document appears to be empty or could not be indexed")
                return b'', b''
            
            print(f"‚úÖ [ANALYZE] –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
            print(f"   - –°–æ–∑–¥–∞–Ω–æ {len(coords_dictionary)} run-–æ–≤")
            print(f"   - –†–∞–∑–º–µ—Ä –∫–∞—Ä—Ç—ã –¥–ª—è Gemini: {len(map_for_gemini)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"   - –ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤ –∫–∞—Ä—Ç—ã: {map_for_gemini[:500]}...")
            
            # Step 3: Call Gemini for document analysis
            print(f"ü§ñ [GEMINI] –û—Ç–ø—Ä–∞–≤–ª—è—é –∫–∞—Ä—Ç—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ Gemini –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞...")
            prompt = self.prompt_manager.get_document_analysis_prompt(map_for_gemini)
            print(f"üîç [GEMINI] –°–æ–∑–¥–∞–Ω –ø—Ä–æ–º–ø—Ç –¥–ª–∏–Ω–æ–π {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # Send request to Gemini
            gemini_response = await self._send_gemini_request(prompt)
            
            if not gemini_response:
                print(f"‚ùå [GEMINI] –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini")
                logger.error("Empty response from Gemini")
                return b'', b''
            
            print(f"‚úÖ [GEMINI] –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç Gemini: {len(gemini_response)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"üîç [GEMINI] –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞: {gemini_response[:200]}...")
            logger.debug(f"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç Gemini: {gemini_response}")
            
            # Step 4: Synchronize documents with modified map
            print(f"üîÑ [ANALYZE] –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É—é –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–∞—Ä—Ç–æ–π...")
            preview_bytes, smart_template_bytes = self._sync_docs_with_map(doc_object, coords_dictionary, gemini_response)
            
            if not preview_bytes or not smart_template_bytes:
                print(f"‚ùå [ANALYZE] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                logger.error("Failed to synchronize documents with modified map")
                return b'', b''
            
            print(f"‚úÖ [ANALYZE] –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ:")
            print(f"   - Preview —Ñ–∞–π–ª: {len(preview_bytes)} –±–∞–π—Ç")
            print(f"   - Smart template —Ñ–∞–π–ª: {len(smart_template_bytes)} –±–∞–π—Ç")
            
            return preview_bytes, smart_template_bytes
            
        except Exception as e:
            print(f"‚ùå [ANALYZE] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            print(f"‚ùå [ANALYZE] –¢–∏–ø –æ—à–∏–±–∫–∏: {type(e).__name__}")
            import traceback
            print(f"‚ùå [ANALYZE] –ü–æ–ª–Ω—ã–π traceback:")
            traceback.print_exc()
            logger.error(f"Error in document analysis: {e}")
            logger.error(f"Full traceback: {traceback.format_exc()}")
            return b'', b''
    
    def _extract_text_from_docx(self, file_bytes: bytes) -> str:
        """
        Extract text content from a DOCX file and convert to Markdown format.
        
        Args:
            file_bytes: Document content as bytes
            
        Returns:
            Extracted text content in Markdown format
        """
        try:
            # Create temporary files for input and output
            with tempfile.NamedTemporaryFile(suffix='.docx', delete=False) as temp_docx:
                temp_docx.write(file_bytes)
                temp_docx_path = temp_docx.name
            
            with tempfile.NamedTemporaryFile(suffix='.md', delete=False) as temp_md:
                temp_md_path = temp_md.name
            
            try:
                # Convert DOCX to Markdown using docx2markdown
                docx_to_markdown(temp_docx_path, temp_md_path)
                
                # Read the generated markdown file
                with open(temp_md_path, 'r', encoding='utf-8') as md_file:
                    markdown_text = md_file.read()
                
                if markdown_text:
                    logger.info(f"Extracted {len(markdown_text)} characters from document in Markdown format")
                    return markdown_text
                else:
                    logger.warning("No text extracted from DOCX document")
                    return ""
                    
            finally:
                # Clean up temporary files
                try:
                    os.unlink(temp_docx_path)
                    os.unlink(temp_md_path)
                except OSError:
                    pass
            
        except Exception as e:
            logger.error(f"Error extracting text from DOCX: {e}")
            return ""
    
    def _extract_text_from_doc(self, file_bytes: bytes) -> str:
        """
        Extract text content from a DOC file.
        
        Args:
            file_bytes: Document content as bytes
            
        Returns:
            Extracted text content
        """
        try:
            # Create BytesIO object from bytes
            doc_stream = BytesIO(file_bytes)
            
            # Use docx2txt to extract text from DOC file
            text = docx2txt.process(doc_stream)
            
            if text:
                logger.info(f"Extracted {len(text)} characters from DOC document")
                return text
            else:
                logger.warning("No text extracted from DOC document")
                return ""
            
        except Exception as e:
            logger.error(f"Error extracting text from DOC: {e}")
            return ""
    
    def _create_simple_prompt(self, document_text: str) -> str:
        """
        Create comprehensive prompt for Gemini to analyze the document.
        
        Args:
            document_text: Text content of the document
            
        Returns:
            Formatted prompt for Gemini
        """
        prompt = self.prompt_manager.get_document_analysis_prompt(document_text)
        print(f"üîç [PROMPT] –°–æ–∑–¥–∞–Ω –ø—Ä–æ–º–ø—Ç –¥–ª–∏–Ω–æ–π {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"üîç [PROMPT] –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –ø—Ä–æ–º–ø—Ç–∞: {prompt[:200]}")
        return prompt
    
    async def _send_gemini_request(self, prompt: str) -> str:
        """
        Send request to Gemini API.
        
        Args:
            prompt: Prompt to send to Gemini
            
        Returns:
            Response from Gemini
        """
        try:
            print(f"üöÄ [GEMINI] –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –≤ Gemini API...")
            
            # Generate content using Gemini
            response = self.model.generate_content(prompt)
            
            if response.text:
                print(f"‚úÖ [GEMINI] –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç Gemini: {len(response.text)} —Å–∏–º–≤–æ–ª–æ–≤")
                print(f"üîç [GEMINI] –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞: {response.text[:200]}")
                print(f"üîç [GEMINI] –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini:")
                print(f"üîç [GEMINI] {response.text}")
                logger.info("Received response from Gemini")
                return response.text
            else:
                print(f"‚ùå [GEMINI] –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini")
                logger.error("Empty response from Gemini")
                return ""
                
        except Exception as e:
            print(f"‚ùå [GEMINI] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –∑–∞–ø—Ä–æ—Å–∞ –≤ Gemini: {e}")
            logger.error(f"Error sending request to Gemini: {e}")
            return ""
    
    def _create_preview_file(self, file_bytes: bytes, replacements: List[Dict[str, str]]) -> bytes:
        """
        Create preview file with red markers for user fields.
        
        Args:
            file_bytes: Original document bytes
            replacements: List of field replacements from Gemini
            
        Returns:
            Modified document bytes with red markers
        """
        try:
            print(f"üîß [PREVIEW] –°–æ–∑–¥–∞—é —Ñ–∞–π–ª –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞...")
            
            # Create BytesIO object from input bytes
            doc_stream = BytesIO(file_bytes)
            
            # Load document using python-docx
            doc = Document(doc_stream)
            
            # Create replacement mapping for preview with unique keys
            preview_replacements = {}
            field_counters = {'PARTY_2_NAME': 0, 'PARTY_2_REQUISITES': 0, 'PARTY_2_DIRECTOR_NAME': 0}
            print(f"üîç [PREVIEW] –ü–æ–ª—É—á–µ–Ω–æ {len(replacements)} –∑–∞–º–µ–Ω –æ—Ç Gemini:")
            for i, replacement in enumerate(replacements):
                print(f"üîç [PREVIEW] –ó–∞–º–µ–Ω–∞ {i+1}: type='{replacement['type']}', text='{replacement['original_text'][:50]}...'")
            
            for replacement in replacements:
                original_text = replacement['original_text']
                field_type = replacement['type']
                
                print(f"üîç [PREVIEW] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–º–µ–Ω—É: type='{field_type}', text='{original_text[:50]}...'")
                
                if field_type == 'PARTY_2_NAME':
                    field_counters['PARTY_2_NAME'] += 1
                    unique_key = f"{original_text}_{field_counters['PARTY_2_NAME']}"
                    preview_replacements[unique_key] = {
                        'original_text': original_text,
                        'replacement': '[–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞]'
                    }
                    print(f"‚úÖ [PREVIEW] –°–æ–∑–¥–∞–Ω–∞ –∑–∞–º–µ–Ω–∞ PARTY_2_NAME: '{original_text[:30]}...' -> '[–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞]'")
                elif field_type == 'PARTY_2_REQUISITES':
                    field_counters['PARTY_2_REQUISITES'] += 1
                    # –î–ª—è —Ä–µ–∫–≤–∏–∑–∏—Ç–æ–≤ –∑–∞–º–µ–Ω—è–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É –±–ª–æ–∫–∞ –æ—Ç–¥–µ–ª—å–Ω–æ,
                    # —á—Ç–æ–±—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –ø–æ–ø–∞—Å—Ç—å –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
                    lines = [l for l in original_text.split('\n') if l.strip()]
                    for i, ln in enumerate(lines):
                        unique_key = f"{ln}_{field_counters['PARTY_2_REQUISITES']}_{i}"
                        preview_replacements[unique_key] = {
                            'original_text': ln,
                            'replacement': '[–†–µ–∫–≤–∏–∑–∏—Ç—ã –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞]'
                        }
                        print(f"‚úÖ [PREVIEW] –°–æ–∑–¥–∞–Ω–∞ –∑–∞–º–µ–Ω–∞ PARTY_2_REQUISITES: '{ln[:30]}...' -> '[–†–µ–∫–≤–∏–∑–∏—Ç—ã –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞]'")
                elif field_type == 'PARTY_2_DIRECTOR_NAME':
                    field_counters['PARTY_2_DIRECTOR_NAME'] += 1
                    unique_key = f"{original_text}_{field_counters['PARTY_2_DIRECTOR_NAME']}"
                    preview_replacements[unique_key] = {
                        'original_text': original_text,
                        'replacement': '[–ò–º—è –î–∏—Ä–µ–∫—Ç–æ—Ä–∞]'
                    }
                    print(f"‚úÖ [PREVIEW] –°–æ–∑–¥–∞–Ω–∞ –∑–∞–º–µ–Ω–∞ PARTY_2_DIRECTOR_NAME: '{original_text[:30]}...' -> '[–ò–º—è –î–∏—Ä–µ–∫—Ç–æ—Ä–∞]'")
                else:
                    print(f"‚ö†Ô∏è [PREVIEW] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –ø–æ–ª—è: '{field_type}'")
            
            print(f"‚úÖ [PREVIEW] –°–æ–∑–¥–∞–Ω–æ {len(preview_replacements)} –∑–∞–º–µ–Ω –¥–ª—è –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞")
            
            # Apply replacements to document with order preservation
            self._apply_replacements_to_document_ordered(doc, preview_replacements, is_preview=True)
            
            # Save modified document to memory
            output_stream = BytesIO()
            doc.save(output_stream)
            output_bytes = output_stream.getvalue()
            
            print(f"‚úÖ [PREVIEW] –§–∞–π–ª –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–æ–∑–¥–∞–Ω: {len(output_bytes)} –±–∞–π—Ç")
            logger.info(f"Preview file created successfully. Output size: {len(output_bytes)} bytes")
            return output_bytes
            
        except Exception as e:
            print(f"‚ùå [PREVIEW] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞ –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞: {e}")
            logger.error(f"Error creating preview file: {e}")
            return b''
    
    def _create_smart_template(self, file_bytes: bytes, replacements: List[Dict[str, str]]) -> bytes:
        """
        Create smart template with standardized placeholders.
        
        Args:
            file_bytes: Original document bytes
            replacements: List of field replacements from Gemini
            
        Returns:
            Modified document bytes with smart placeholders
        """
        try:
            print(f"üîß [SMART] –°–æ–∑–¥–∞—é —É–º–Ω—ã–π —à–∞–±–ª–æ–Ω...")
            print(f"üîç [SMART] –ü–æ–ª—É—á–µ–Ω–æ {len(replacements)} –∑–∞–º–µ–Ω –æ—Ç Gemini:")
            for i, replacement in enumerate(replacements):
                print(f"üîç [SMART] –ó–∞–º–µ–Ω–∞ {i+1}: type='{replacement['type']}', text='{replacement['original_text'][:50]}...'")
            
            # Create BytesIO object from input bytes
            doc_stream = BytesIO(file_bytes)
            
            # Load document using python-docx
            doc = Document(doc_stream)
            
            # Create replacement mapping for smart template
            smart_replacements = {}
            field_counters = {'PARTY_2_NAME': 0, 'PARTY_2_REQUISITES': 0, 'PARTY_2_DIRECTOR_NAME': 0}
            
            for replacement in replacements:
                original_text = replacement['original_text']
                field_type = replacement['type']
                
                print(f"üîç [SMART] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–º–µ–Ω—É: type='{field_type}', text='{original_text[:50]}...'")
                
                if field_type == 'PARTY_2_NAME':
                    field_counters['PARTY_2_NAME'] += 1
                    # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–º–µ–Ω—ã
                    unique_key = f"{original_text}_{field_counters['PARTY_2_NAME']}"
                    smart_replacements[unique_key] = {
                        'original_text': original_text,
                        'replacement': '{{PARTY_2_NAME}}'
                    }
                    print(f"‚úÖ [SMART] –°–æ–∑–¥–∞–Ω–∞ –∑–∞–º–µ–Ω–∞ PARTY_2_NAME: '{original_text[:30]}...' -> '{{PARTY_2_NAME}}'")
                elif field_type == 'PARTY_2_REQUISITES':
                    field_counters['PARTY_2_REQUISITES'] += 1
                    # –î–ª—è —Ä–µ–∫–≤–∏–∑–∏—Ç–æ–≤ –∑–∞–º–µ–Ω—è–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É –±–ª–æ–∫–∞ –æ—Ç–¥–µ–ª—å–Ω–æ –Ω–∞ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä —Ä–µ–∫–≤–∏–∑–∏—Ç–æ–≤
                    lines = [l for l in original_text.split('\n') if l.strip()]
                    for i, ln in enumerate(lines):
                        unique_key = f"{ln}_{field_counters['PARTY_2_REQUISITES']}_{i}"
                        smart_replacements[unique_key] = {
                            'original_text': ln,
                            'replacement': '{{PARTY_2_REQUISITES}}'
                        }
                        print(f"‚úÖ [SMART] –°–æ–∑–¥–∞–Ω–∞ –∑–∞–º–µ–Ω–∞ PARTY_2_REQUISITES: '{ln[:30]}...' -> '{{PARTY_2_REQUISITES}}'")
                elif field_type == 'PARTY_2_DIRECTOR_NAME':
                    field_counters['PARTY_2_DIRECTOR_NAME'] += 1
                    # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–º–µ–Ω—ã
                    unique_key = f"{original_text}_{field_counters['PARTY_2_DIRECTOR_NAME']}"
                    smart_replacements[unique_key] = {
                        'original_text': original_text,
                        'replacement': '{{PARTY_2_DIRECTOR_NAME}}'
                    }
                    print(f"‚úÖ [SMART] –°–æ–∑–¥–∞–Ω–∞ –∑–∞–º–µ–Ω–∞ PARTY_2_DIRECTOR_NAME: '{original_text[:30]}...' -> '{{PARTY_2_DIRECTOR_NAME}}'")
                else:
                    print(f"‚ö†Ô∏è [SMART] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –ø–æ–ª—è: '{field_type}'")
            
            print(f"‚úÖ [SMART] –°–æ–∑–¥–∞–Ω–æ {len(smart_replacements)} –∑–∞–º–µ–Ω –¥–ª—è —É–º–Ω–æ–≥–æ —à–∞–±–ª–æ–Ω–∞")
            print(f"üîç [SMART] –ò—Ç–æ–≥–æ–≤—ã–µ –∑–∞–º–µ–Ω—ã:")
            for original, replacement in smart_replacements.items():
                print(f"üîç [SMART] '{original[:30]}...' -> '{replacement}'")
            
            # Apply replacements to document with order preservation
            self._apply_replacements_to_document_ordered(doc, smart_replacements, is_preview=False)
            
            # Save modified document to memory
            output_stream = BytesIO()
            doc.save(output_stream)
            output_bytes = output_stream.getvalue()
            
            print(f"‚úÖ [SMART] –£–º–Ω—ã–π —à–∞–±–ª–æ–Ω —Å–æ–∑–¥–∞–Ω: {len(output_bytes)} –±–∞–π—Ç")
            logger.info(f"Smart template created successfully. Output size: {len(output_bytes)} bytes")
            return output_bytes
            
        except Exception as e:
            print(f"‚ùå [SMART] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —É–º–Ω–æ–≥–æ —à–∞–±–ª–æ–Ω–∞: {e}")
            logger.error(f"Error creating smart template: {e}")
            return b''
    
    def _apply_replacements_to_document(self, doc: Document, replacements: Dict[str, str], is_preview: bool = True):
        """
        Apply replacements to document while preserving formatting.
        
        Args:
            doc: python-docx Document object
            replacements: Dictionary mapping original text to replacement text
            is_preview: Whether this is for preview (red formatting) or smart template
        """
        try:
            print(f"üîß [APPLY] –ü—Ä–∏–º–µ–Ω—è—é {len(replacements)} –∑–∞–º–µ–Ω –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É...")
            
            # Process all paragraphs
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    self._apply_replacements_to_paragraph(paragraph, replacements, is_preview)
            
            # Process all tables
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        for paragraph in cell.paragraphs:
                            if paragraph.text.strip():
                                self._apply_replacements_to_paragraph(paragraph, replacements, is_preview)
            
            print(f"‚úÖ [APPLY] –ó–∞–º–µ–Ω—ã –ø—Ä–∏–º–µ–Ω–µ–Ω—ã –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É")
            
        except Exception as e:
            print(f"‚ùå [APPLY] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –∑–∞–º–µ–Ω: {e}")
            logger.error(f"Error applying replacements to document: {e}")
    
    def _apply_replacements_to_document_ordered(self, doc: Document, smart_replacements: Dict[str, Dict], is_preview: bool = True):
        """
        Apply replacements to document with order preservation for identical text.
        
        Args:
            doc: python-docx Document object
            smart_replacements: Dictionary with unique keys and replacement data
            is_preview: Whether this is for preview (red formatting) or smart template
        """
        try:
            print(f"üîß [APPLY] –ü—Ä–∏–º–µ–Ω—è—é {len(smart_replacements)} –∑–∞–º–µ–Ω –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–æ—Ä—è–¥–∫–∞...")
            
            # Convert to list of replacements with order
            replacements_list = []
            for key, data in smart_replacements.items():
                replacements_list.append({
                    'original_text': data['original_text'],
                    'replacement': data['replacement']
                })
            
            # Process all paragraphs
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    self._apply_replacements_to_paragraph_ordered(paragraph, replacements_list, is_preview)
            
            # Process all tables
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        for paragraph in cell.paragraphs:
                            if paragraph.text.strip():
                                self._apply_replacements_to_paragraph_ordered(paragraph, replacements_list, is_preview)
            
            print(f"‚úÖ [APPLY] –ó–∞–º–µ–Ω—ã –ø—Ä–∏–º–µ–Ω–µ–Ω—ã –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–æ—Ä—è–¥–∫–∞")
            
        except Exception as e:
            print(f"‚ùå [APPLY] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –∑–∞–º–µ–Ω —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–æ—Ä—è–¥–∫–∞: {e}")
            logger.error(f"Error applying ordered replacements to document: {e}")
    
    def _apply_replacements_to_paragraph_ordered(self, paragraph, replacements_list: List[Dict], is_preview: bool = True):
        """
        Apply replacements to paragraph with order preservation.
        
        Args:
            paragraph: python-docx paragraph object
            replacements_list: List of replacement dictionaries
            is_preview: Whether this is for preview (red formatting) or smart template
        """
        try:
            original_text = paragraph.text
            
            # Apply replacements in order, but only once per occurrence
            applied_replacements = set()
            
            for replacement in replacements_list:
                original_part = replacement['original_text']
                replacement_text = replacement['replacement']
                
                if not original_part.strip():
                    continue
                
                # Check if this paragraph contains the replacement text
                if original_part in original_text:
                    # Create a unique identifier for this replacement
                    replacement_id = f"{original_part}_{original_text.find(original_part)}"
                    
                    if replacement_id not in applied_replacements:
                        # Apply the replacement
                        new_text = original_text.replace(original_part, replacement_text, 1)  # Replace only first occurrence
                        if new_text != original_text:
                            print(f"üîç [REPLACE] –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ:")
                            print(f"üîç [REPLACE] –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞: '{original_text[:50]}...'")
                            print(f"üîç [REPLACE] –ò—â–µ–º: '{original_part[:50]}...'")
                            print(f"üîç [REPLACE] –ó–∞–º–µ–Ω—è–µ–º –Ω–∞: '{replacement_text}'")
                            print(f"üîç [REPLACE] –¢–∏–ø —Ñ–∞–π–ª–∞: {'–ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä' if is_preview else '—É–º–Ω—ã–π —à–∞–±–ª–æ–Ω'}")
                            
                            # Update paragraph text
                            paragraph.text = new_text
                            original_text = new_text  # Update for next iteration
                            applied_replacements.add(replacement_id)
                            
                            print(f"‚úÖ [REPLACE] –ü—Ä–∏–º–µ–Ω–µ–Ω–∞ –∑–∞–º–µ–Ω–∞: '{original_part[:30]}...' -> '{replacement_text}'")
                            
        except Exception as e:
            print(f"‚ùå [REPLACE] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–º–µ–Ω–µ –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ: {e}")
            logger.error(f"Error applying replacement to paragraph: {e}")
    
    def _apply_replacements_to_paragraph(self, paragraph, replacements: Dict[str, str], is_preview: bool = True):
        """
        Apply replacements to paragraph while preserving formatting.
        
        Args:
            paragraph: python-docx paragraph object
            replacements: Dictionary mapping original text to replacement text
            is_preview: Whether this is for preview (red formatting) or smart template
        """
        try:
            original_text = paragraph.text
            
            # Check if this paragraph contains any replacement (—Å—Ç—Ä–æ–≥–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –¥–ª—è —Å—Ç—Ä–æ–∫ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–π)
            for original_part, replacement_text in replacements.items():
                if not original_part.strip():
                    continue
                # –î–ª—è –ª–∏–Ω–∏–π –∏–∑ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–π –∏ –ø—Ä–æ–±–µ–ª–æ–≤ —Ç—Ä–µ–±—É–µ–º —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è,
                # —á—Ç–æ–±—ã –∫–æ—Ä–æ—Ç–∫–∏–µ –ª–∏–Ω–∏–∏ (–¥–∏—Ä–µ–∫—Ç–æ—Ä) –Ω–µ –∑–∞–º–µ–Ω—è–ª–∏ –¥–ª–∏–Ω–Ω—ã–µ (—Ä–µ–∫–≤–∏–∑–∏—Ç—ã)
                is_underscore_only = bool(re.fullmatch(r"[_\s]+", original_part))
                match = (original_text == original_part) if is_underscore_only else (original_part in original_text)
                if match:
                    print(f"üîç [REPLACE] –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ:")
                    print(f"üîç [REPLACE] –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞: '{original_text[:100]}...'")
                    print(f"üîç [REPLACE] –ò—â–µ–º: '{original_part[:50]}...'")
                    print(f"üîç [REPLACE] –ó–∞–º–µ–Ω—è–µ–º –Ω–∞: '{replacement_text}'")
                    print(f"üîç [REPLACE] –¢–∏–ø —Ñ–∞–π–ª–∞: {'–ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä' if is_preview else '—É–º–Ω—ã–π —à–∞–±–ª–æ–Ω'}")
                    
                    # Clear the paragraph
                    paragraph.clear()
                    
                    # Split text around the original part
                    parts = ["", ""] if original_text == original_part else original_text.split(original_part)
                    
                    # Add text before the field
                    if parts[0]:
                        paragraph.add_run(parts[0])
                    
                    # Add replacement text with formatting
                    replacement_run = paragraph.add_run(replacement_text)
                    if is_preview:
                        # –£–¥–∞–ª—è–µ–º –∂–µ–ª—Ç—É—é –∑–∞–ª–∏–≤–∫—É –ø–µ—Ä–µ–¥ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                        self._remove_highlighting(replacement_run)
                        # Red formatting for preview
                        replacement_run.font.color.rgb = RGBColor(255, 0, 0)  # Red color
                        replacement_run.font.bold = True
                    
                    # Add text after the field
                    if len(parts) > 1 and parts[1]:
                        paragraph.add_run(parts[1])
                    
                    print(f"‚úÖ [REPLACE] –ü—Ä–∏–º–µ–Ω–µ–Ω–∞ –∑–∞–º–µ–Ω–∞: '{original_part[:30]}...' -> '{replacement_text}'")
                    break
            
        except Exception as e:
            print(f"‚ùå [REPLACE] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –∑–∞–º–µ–Ω—ã: {e}")
            logger.error(f"Error applying replacement to paragraph: {e}")
    

    def _parse_gemini_response(self, response: str) -> List[Dict[str, str]]:
        """
        Parse JSON response from Gemini.

        Args:
            response: Raw response from Gemini

        Returns:
            List of field data dictionaries
        """
        try:
            print(f"üîç [PARSE] –ù–∞—á–∏–Ω–∞—é –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Gemini...")
            print(f"üîç [PARSE] –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(response)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"üîç [PARSE] –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞: {response[:200]}")
            
            # Clean the response (remove markdown formatting if present)
            cleaned_response = response.strip()
            
            # Remove markdown code blocks
            if cleaned_response.startswith('```json'):
                cleaned_response = cleaned_response[7:]
            elif cleaned_response.startswith('```'):
                cleaned_response = cleaned_response[3:]
            
            if cleaned_response.endswith('```'):
                cleaned_response = cleaned_response[:-3]
            
            cleaned_response = cleaned_response.strip()
            
            print(f"üîç [PARSE] –û—á–∏—â–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {cleaned_response[:100]}...")
            
            # Try multiple parsing strategies
            field_data = None
            
            # Strategy 1: Try to find JSON array in the response
            json_start = cleaned_response.find('[')
            json_end = cleaned_response.rfind(']') + 1
            
            if json_start != -1 and json_end > json_start:
                json_text = cleaned_response[json_start:json_end]
                print(f"üîç [PARSE] –ù–∞–π–¥–µ–Ω JSON –º–∞—Å—Å–∏–≤: –ø–æ–∑–∏—Ü–∏—è {json_start} - {json_end}")
                print(f"üîç [PARSE] JSON —Ç–µ–∫—Å—Ç: {json_text[:200]}...")
                try:
                    field_data = json.loads(json_text)
                    print(f"‚úÖ [PARSE] –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω JSON –º–∞—Å—Å–∏–≤")
                except json.JSONDecodeError as e:
                    print(f"‚ùå [PARSE] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –º–∞—Å—Å–∏–≤–∞: {e}")
                    field_data = None
            
            # Strategy 2: Try to parse the whole response
            if field_data is None:
                try:
                    field_data = json.loads(cleaned_response)
                    print(f"‚úÖ [PARSE] –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω –≤–µ—Å—å –æ—Ç–≤–µ—Ç")
                except json.JSONDecodeError as e:
                    print(f"‚ùå [PARSE] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")
                    field_data = None
            
            # Strategy 3: Try to extract JSON using regex
            if field_data is None:
                json_pattern = r'\[.*?\]'
                json_matches = re.findall(json_pattern, cleaned_response, re.DOTALL)
                if json_matches:
                    for json_match in json_matches:
                        try:
                            field_data = json.loads(json_match)
                            print(f"‚úÖ [PARSE] –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω JSON —á–µ—Ä–µ–∑ regex")
                            break
                        except json.JSONDecodeError:
                            continue
            
            if field_data is None:
                print(f"‚ùå [PARSE] –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞")
                logger.error("Could not parse JSON from Gemini response")
                return []

            if not isinstance(field_data, list):
                logger.error("Gemini response is not a list")
                print(f"‚ùå [PARSE] –û—Ç–≤–µ—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –º–∞—Å—Å–∏–≤–æ–º: {type(field_data)}")
                return []

            # Validate that each item has required fields
            valid_fields = []
            for i, item in enumerate(field_data):
                print(f"üîç [PARSE] –ü—Ä–æ–≤–µ—Ä—è—é —ç–ª–µ–º–µ–Ω—Ç {i}: {item}")
                if isinstance(item, dict) and 'original_text' in item and 'type' in item:
                    if item['type'] in ['PARTY_2_NAME', 'PARTY_2_REQUISITES', 'PARTY_2_DIRECTOR_NAME']:
                        valid_fields.append(item)
                        print(f"‚úÖ [PARSE] –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ: {item['type']} -> '{item['original_text'][:50]}...'")
                        print(f"üîç [PARSE] –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ–ª—è: '{item['original_text']}'")
                    else:
                        print(f"‚ö†Ô∏è [PARSE] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –ø–æ–ª—è: {item['type']}")
                else:
                    print(f"‚ö†Ô∏è [PARSE] –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –ø–æ–ª—è: {item}")
            
            print(f"üîç [PARSE] –ò—Ç–æ–≥–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ –≤–∞–ª–∏–¥–Ω—ã—Ö –ø–æ–ª–µ–π:")
            for i, field in enumerate(valid_fields):
                print(f"üîç [PARSE] –ü–æ–ª–µ {i+1}: type='{field['type']}', text='{field['original_text'][:100]}...'")
            
            logger.info(f"Successfully parsed {len(valid_fields)} valid fields from Gemini response")
            return valid_fields

        except json.JSONDecodeError as e:
            logger.error(f"Error parsing JSON response from Gemini: {e}")
            logger.error(f"Raw response: {response}")
            print(f"‚ùå [PARSE] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            print(f"‚ùå [PARSE] –ò—Å—Ö–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç: {response[:500]}...")
            return []
        except Exception as e:
            logger.error(f"Unexpected error parsing Gemini response: {e}")
            print(f"‚ùå [PARSE] –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            return []