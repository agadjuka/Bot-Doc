"""
Template Processor Service for automatic field detection and marking in documents.
This service analyzes documents and identifies fields that need to be filled with company data.
"""

import json
import logging
import os
import re
import tempfile
import io
import copy
from typing import Dict, List, Tuple
from io import BytesIO

import google.generativeai as genai
from google.oauth2 import service_account
from docx import Document
from docx.shared import RGBColor
import docx2txt
from docx2markdown._docx_to_markdown import docx_to_markdown

from config.prompts import PromptManager

logger = logging.getLogger(__name__)


class TemplateProcessorService:
    """
    Service for processing document templates using simplified analysis strategy.
    Analyzes documents and creates two files: preview for user and smart template for storage.
    """
    
    def __init__(self):
        """
        Initialize the TemplateProcessorService using Google Cloud authentication.
        """
        self.prompt_manager = PromptManager()
        self._initialize_gemini()
        logger.info("TemplateProcessorService initialized successfully")
    
    def _initialize_gemini(self):
        """Initialize Google Gemini AI service using Google Cloud authentication"""
        try:
            # Get credentials file path
            credentials_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
            if not credentials_path:
                logger.error("GOOGLE_APPLICATION_CREDENTIALS not set")
                raise ValueError("GOOGLE_APPLICATION_CREDENTIALS is required")
            
            if not os.path.exists(credentials_path):
                logger.error(f"Credentials file not found: {credentials_path}")
                raise FileNotFoundError(f"Credentials file not found: {credentials_path}")
            
            # Load service account credentials
            credentials = service_account.Credentials.from_service_account_file(
                credentials_path,
                scopes=['https://www.googleapis.com/auth/generative-language']
            )
            
            # Configure Gemini API with service account credentials
            genai.configure(credentials=credentials)
            
            # Initialize model (using flash model for better performance)
            self.model = genai.GenerativeModel('gemini-2.5-flash')
            logger.info("Gemini AI service initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize Gemini AI service: {e}")
            raise
    
    def _index_runs_and_build_map(self, doc_object: Document) -> Tuple[str, Dict[str, any]]:
        """
        Create detailed indexing of document at run level for precise analysis.
        
        Args:
            doc_object: python-docx Document object
            
        Returns:
            Tuple of (map_for_gemini, coords_dictionary)
            - map_for_gemini: Text map of document with run IDs for AI analysis
            - coords_dictionary: Python dictionary for quick navigation by run IDs
        """
        try:
            print(f"üîç [INDEX] –ù–∞—á–∏–Ω–∞—é –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ run-–æ–≤...")
            
            # Initialize variables
            map_for_gemini = ""
            coords_dictionary = {}
            run_counter = 0
            
            # Process all paragraphs
            for paragraph in doc_object.paragraphs:
                for run in paragraph.runs:
                    # Generate unique ID for this run
                    run_id = f"run-{run_counter}"
                    
                    # Add run to coordinates dictionary (save direct reference to object)
                    coords_dictionary[run_id] = run
                    
                    # Add run to map for Gemini
                    map_for_gemini += f"[{run_id}]{run.text}"
                    
                    # Increment counter
                    run_counter += 1
                
                # Add newline after each paragraph to preserve structure
                map_for_gemini += "\n"
            
            # Process all tables
            for table in doc_object.tables:
                for row in table.rows:
                    for cell in row.cells:
                        for paragraph in cell.paragraphs:
                            for run in paragraph.runs:
                                # Generate unique ID for this run
                                run_id = f"run-{run_counter}"
                                
                                # Add run to coordinates dictionary
                                coords_dictionary[run_id] = run
                                
                                # Add run to map for Gemini
                                map_for_gemini += f"[{run_id}]{run.text}"
                                
                                # Increment counter
                                run_counter += 1
                            
                            # Add newline after each paragraph in table cells
                            map_for_gemini += "\n"
            
            print(f"‚úÖ [INDEX] –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
            print(f"   - –°–æ–∑–¥–∞–Ω–æ {len(coords_dictionary)} run-–æ–≤")
            print(f"   - –†–∞–∑–º–µ—Ä –∫–∞—Ä—Ç—ã –¥–ª—è Gemini: {len(map_for_gemini)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"   - –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –∫–∞—Ä—Ç—ã: {map_for_gemini[:200]}...")
            
            return map_for_gemini, coords_dictionary
            
        except Exception as e:
            print(f"‚ùå [INDEX] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            logger.error(f"Error indexing document runs: {e}")
            return "", {}
    
    def _apply_edits_to_runs(self, doc_object: Document, edits_plan: List[Dict[str, str]], coords_dictionary: Dict[str, any]) -> Tuple[bytes, bytes]:
        """
        Apply surgical edits to document runs based on Gemini's edits plan.
        This is the heart of our "surgical" module for precise run-level modifications.
        
        Args:
            doc_object: Original Document object
            edits_plan: List of edit plans from Gemini with run_id and field_name
            coords_dictionary: Dictionary mapping run_id to run objects
            
        Returns:
            Tuple of (preview_bytes, smart_template_bytes)
        """
        try:
            print(f"üîß [SURGERY] –ù–∞—á–∏–Ω–∞—é —Ö–∏—Ä—É—Ä–≥–∏—é run-–æ–≤...")
            print(f"üîß [SURGERY] –ü–æ–ª—É—á–µ–Ω–æ {len(edits_plan)} –ø—Ä–∞–≤–æ–∫ –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è")
            
            # Step 1: Create deep copies of the original document
            print(f"üìã [SURGERY] –°–æ–∑–¥–∞—é –≥–ª—É–±–æ–∫–∏–µ –∫–æ–ø–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞...")
            preview_doc = copy.deepcopy(doc_object)
            smart_template_doc = copy.deepcopy(doc_object)
            print(f"‚úÖ [SURGERY] –°–æ–∑–¥–∞–Ω—ã –¥–≤–µ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ –∫–æ–ø–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
            
            # Step 2: Rebuild coordinates dictionary for both copies
            print(f"üîç [SURGERY] –ü–µ—Ä–µ—Å—Ç—Ä–∞–∏–≤–∞—é —Å–ª–æ–≤–∞—Ä–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –¥–ª—è –∫–æ–ø–∏–π...")
            _, preview_coords_dictionary = self._index_runs_and_build_map(preview_doc)
            _, smart_template_coords_dictionary = self._index_runs_and_build_map(smart_template_doc)
            print(f"‚úÖ [SURGERY] –°–ª–æ–≤–∞—Ä–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –ø–µ—Ä–µ—Å—Ç—Ä–æ–µ–Ω—ã:")
            print(f"   - Preview: {len(preview_coords_dictionary)} run-–æ–≤")
            print(f"   - Smart template: {len(smart_template_coords_dictionary)} run-–æ–≤")
            
            # Step 3: Apply edits to both documents
            print(f"üîß [SURGERY] –ü—Ä–∏–º–µ–Ω—è—é –ø—Ä–∞–≤–∫–∏ –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º...")
            for i, edit in enumerate(edits_plan):
                run_id = edit.get('run_id')
                field_name = edit.get('field_name')
                
                print(f"üîß [SURGERY] –ü—Ä–∞–≤–∫–∞ {i+1}/{len(edits_plan)}: run_id='{run_id}', field_name='{field_name}'")
                
                if not run_id or not field_name:
                    print(f"‚ö†Ô∏è [SURGERY] –ü—Ä–æ–ø—É—Å–∫–∞—é –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é –ø—Ä–∞–≤–∫—É: {edit}")
                    continue
                
                # Find target runs in both documents
                preview_run = preview_coords_dictionary.get(run_id)
                smart_template_run = smart_template_coords_dictionary.get(run_id)
                
                if not preview_run:
                    print(f"‚ö†Ô∏è [SURGERY] Run {run_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ preview –¥–æ–∫—É–º–µ–Ω—Ç–µ")
                    continue
                    
                if not smart_template_run:
                    print(f"‚ö†Ô∏è [SURGERY] Run {run_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ smart template –¥–æ–∫—É–º–µ–Ω—Ç–µ")
                    continue
                
                print(f"üîç [SURGERY] –ù–∞–π–¥–µ–Ω—ã —Ü–µ–ª–µ–≤—ã–µ run-—ã:")
                print(f"   - Preview run text: '{preview_run.text[:50]}...'")
                print(f"   - Smart template run text: '{smart_template_run.text[:50]}...'")
                
                # Apply edit to preview document
                print(f"üé® [SURGERY] –ü—Ä–∏–º–µ–Ω—è—é –ø—Ä–∞–≤–∫—É –∫ preview –¥–æ–∫—É–º–µ–Ω—Ç—É...")
                preview_run.text = ''  # Clear existing text
                preview_run.add_text(f"[{field_name}]")  # Add new marker text
                preview_run.font.color.rgb = RGBColor(255, 0, 0)  # Red color
                preview_run.bold = True  # Bold formatting
                print(f"‚úÖ [SURGERY] Preview run –æ–±–Ω–æ–≤–ª–µ–Ω: '{preview_run.text}' (–∫—Ä–∞—Å–Ω—ã–π, –∂–∏—Ä–Ω—ã–π)")
                
                # Apply edit to smart template document
                print(f"üîß [SURGERY] –ü—Ä–∏–º–µ–Ω—è—é –ø—Ä–∞–≤–∫—É –∫ smart template –¥–æ–∫—É–º–µ–Ω—Ç—É...")
                smart_template_run.text = f"{{{{{field_name}}}}}"  # Add smart placeholder
                print(f"‚úÖ [SURGERY] Smart template run –æ–±–Ω–æ–≤–ª–µ–Ω: '{smart_template_run.text}'")
            
            print(f"‚úÖ [SURGERY] –í—Å–µ –ø—Ä–∞–≤–∫–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º")
            
            # Step 4: Save both documents to bytes
            print(f"üíæ [SURGERY] –°–æ—Ö—Ä–∞–Ω—è—é –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –±–∞–π—Ç—ã...")
            
            # Save preview document
            preview_stream = BytesIO()
            preview_doc.save(preview_stream)
            preview_bytes = preview_stream.getvalue()
            print(f"‚úÖ [SURGERY] Preview –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {len(preview_bytes)} –±–∞–π—Ç")
            
            # Save smart template document
            smart_template_stream = BytesIO()
            smart_template_doc.save(smart_template_stream)
            smart_template_bytes = smart_template_stream.getvalue()
            print(f"‚úÖ [SURGERY] Smart template –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {len(smart_template_bytes)} –±–∞–π—Ç")
            
            print(f"üéâ [SURGERY] –•–∏—Ä—É—Ä–≥–∏—è run-–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            return preview_bytes, smart_template_bytes
            
        except Exception as e:
            print(f"‚ùå [SURGERY] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ö–∏—Ä—É—Ä–≥–∏–∏ run-–æ–≤: {e}")
            logger.error(f"Error in surgical edits application: {e}")
            import traceback
            traceback.print_exc()
            return b'', b''
    
    async def analyze_and_prepare_templates(self, file_bytes: bytes, file_format: str = '.docx', debug_callback=None) -> Tuple[bytes, bytes]:
        """
        Analyze document and prepare two files: preview for user and smart template for storage.
        
        Args:
            file_bytes: Document content as bytes
            file_format: File format ('.docx' or '.doc')
            
        Returns:
            Tuple of (preview_bytes, smart_template_bytes)
        """
        try:
            print(f"üìÑ [ANALYZE] –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Ä–∞–∑–º–µ—Ä–æ–º {len(file_bytes)} –±–∞–π—Ç")
            
            # Step 1: Load document using python-docx for precise run-level analysis
            if file_format == '.docx':
                print(f"üìñ [ANALYZE] –ó–∞–≥—Ä—É–∂–∞—é DOCX –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
                doc_object = Document(io.BytesIO(file_bytes))
            elif file_format == '.doc':
                print(f"‚ùå [ANALYZE] DOC —Ñ–æ—Ä–º–∞—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
                return b'', b''
            else:
                print(f"‚ùå [ANALYZE] –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file_format}")
                return b'', b''
            
            # Step 2: Create detailed run-level indexing
            print(f"üîç [ANALYZE] –°–æ–∑–¥–∞—é –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –Ω–∞ —É—Ä–æ–≤–Ω–µ run-–æ–≤...")
            map_for_gemini, coords_dictionary = self._index_runs_and_build_map(doc_object)
            
            if not map_for_gemini.strip():
                print(f"‚ö†Ô∏è [ANALYZE] –î–æ–∫—É–º–µ–Ω—Ç –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å")
                logger.warning("Document appears to be empty or could not be indexed")
                return b'', b''
            
            print(f"‚úÖ [ANALYZE] –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
            print(f"   - –°–æ–∑–¥–∞–Ω–æ {len(coords_dictionary)} run-–æ–≤")
            print(f"   - –†–∞–∑–º–µ—Ä –∫–∞—Ä—Ç—ã –¥–ª—è Gemini: {len(map_for_gemini)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"   - –ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤ –∫–∞—Ä—Ç—ã: {map_for_gemini[:500]}...")
            
            # Step 3: Call Gemini for document analysis
            print(f"ü§ñ [GEMINI] –û—Ç–ø—Ä–∞–≤–ª—è—é –∫–∞—Ä—Ç—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ Gemini –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞...")
            prompt = self.prompt_manager.get_document_analysis_prompt(map_for_gemini)
            print(f"üîç [GEMINI] –°–æ–∑–¥–∞–Ω –ø—Ä–æ–º–ø—Ç –¥–ª–∏–Ω–æ–π {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # Send request to Gemini
            gemini_response = await self._send_gemini_request(prompt, debug_callback)
            
            if not gemini_response:
                print(f"‚ùå [GEMINI] –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini")
                logger.error("Empty response from Gemini")
                return b'', b''
            
            # Parse Gemini response to get edits plan
            print(f"üîç [GEMINI] –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Gemini...")
            edits_plan = self._parse_gemini_edits_plan(gemini_response)
            
            if not edits_plan:
                print(f"‚ùå [GEMINI] –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –ø–ª–∞–Ω –ø—Ä–∞–≤–æ–∫ –æ—Ç Gemini")
                logger.error("Failed to parse edits plan from Gemini response")
                return b'', b''
            
            print(f"‚úÖ [GEMINI] –ü–æ–ª—É—á–µ–Ω –ø–ª–∞–Ω –ø—Ä–∞–≤–æ–∫ –æ—Ç Gemini: {len(edits_plan)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
            logger.debug(f"–ü–æ–ª—É—á–µ–Ω –ø–ª–∞–Ω –ø—Ä–∞–≤–æ–∫ –æ—Ç Gemini: {edits_plan}")
            
            # Step 4: Apply surgical edits to document
            print(f"üîß [ANALYZE] –ü—Ä–∏–º–µ–Ω—è—é —Ö–∏—Ä—É—Ä–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–∞–≤–∫–∏ –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É...")
            preview_bytes, smart_template_bytes = self._apply_edits_to_runs(doc_object, edits_plan, coords_dictionary)
            
            if not preview_bytes or not smart_template_bytes:
                print(f"‚ùå [ANALYZE] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ —Ö–∏—Ä—É—Ä–≥–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∞–≤–æ–∫")
                logger.error("Failed to apply surgical edits to document")
                return b'', b''
            
            print(f"‚úÖ [ANALYZE] –•–∏—Ä—É—Ä–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–∞–≤–∫–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ:")
            print(f"   - Preview —Ñ–∞–π–ª: {len(preview_bytes)} –±–∞–π—Ç")
            print(f"   - Smart template —Ñ–∞–π–ª: {len(smart_template_bytes)} –±–∞–π—Ç")
            
            return preview_bytes, smart_template_bytes
            
        except Exception as e:
            print(f"‚ùå [ANALYZE] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            print(f"‚ùå [ANALYZE] –¢–∏–ø –æ—à–∏–±–∫–∏: {type(e).__name__}")
            import traceback
            print(f"‚ùå [ANALYZE] –ü–æ–ª–Ω—ã–π traceback:")
            traceback.print_exc()
            logger.error(f"Error in document analysis: {e}")
            logger.error(f"Full traceback: {traceback.format_exc()}")
            return b'', b''
    
    def _extract_text_from_docx(self, file_bytes: bytes) -> str:
        """
        Extract text content from a DOCX file and convert to Markdown format.
        
        Args:
            file_bytes: Document content as bytes
            
        Returns:
            Extracted text content in Markdown format
        """
        try:
            # Create temporary files for input and output
            with tempfile.NamedTemporaryFile(suffix='.docx', delete=False) as temp_docx:
                temp_docx.write(file_bytes)
                temp_docx_path = temp_docx.name
            
            with tempfile.NamedTemporaryFile(suffix='.md', delete=False) as temp_md:
                temp_md_path = temp_md.name
            
            try:
                # Convert DOCX to Markdown using docx2markdown
                docx_to_markdown(temp_docx_path, temp_md_path)
                
                # Read the generated markdown file
                with open(temp_md_path, 'r', encoding='utf-8') as md_file:
                    markdown_text = md_file.read()
                
                if markdown_text:
                    logger.info(f"Extracted {len(markdown_text)} characters from document in Markdown format")
                    return markdown_text
                else:
                    logger.warning("No text extracted from DOCX document")
                    return ""
                    
            finally:
                # Clean up temporary files
                try:
                    os.unlink(temp_docx_path)
                    os.unlink(temp_md_path)
                except OSError:
                    pass
            
        except Exception as e:
            logger.error(f"Error extracting text from DOCX: {e}")
            return ""
    
    def _extract_text_from_doc(self, file_bytes: bytes) -> str:
        """
        Extract text content from a DOC file.
        
        Args:
            file_bytes: Document content as bytes
            
        Returns:
            Extracted text content
        """
        try:
            # Create BytesIO object from bytes
            doc_stream = BytesIO(file_bytes)
            
            # Use docx2txt to extract text from DOC file
            text = docx2txt.process(doc_stream)
            
            if text:
                logger.info(f"Extracted {len(text)} characters from DOC document")
                return text
            else:
                logger.warning("No text extracted from DOC document")
                return ""
            
        except Exception as e:
            logger.error(f"Error extracting text from DOC: {e}")
            return ""
    
    def _create_simple_prompt(self, document_text: str) -> str:
        """
        Create comprehensive prompt for Gemini to analyze the document.
        
        Args:
            document_text: Text content of the document
            
        Returns:
            Formatted prompt for Gemini
        """
        prompt = self.prompt_manager.get_document_analysis_prompt(document_text)
        print(f"üîç [PROMPT] –°–æ–∑–¥–∞–Ω –ø—Ä–æ–º–ø—Ç –¥–ª–∏–Ω–æ–π {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"üîç [PROMPT] –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –ø—Ä–æ–º–ø—Ç–∞: {prompt[:200]}")
        return prompt
    
    async def _send_gemini_request(self, prompt: str, debug_callback=None) -> str:
        """
        Send request to Gemini API.
        
        Args:
            prompt: Prompt to send to Gemini
            
        Returns:
            Response from Gemini
        """
        try:
            print(f"üöÄ [GEMINI] –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –≤ Gemini API...")
            
            # Debug: Send prompt to chat if debug_callback is provided
            if debug_callback:
                try:
                    await debug_callback(prompt)
                except Exception as e:
                    print(f"‚ö†Ô∏è [DEBUG] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –ø—Ä–æ–º–ø—Ç–∞ –≤ —á–∞—Ç: {e}")
            
            # Generate content using Gemini
            response = self.model.generate_content(prompt)
            
            if response.text:
                print(f"‚úÖ [GEMINI] –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç Gemini: {len(response.text)} —Å–∏–º–≤–æ–ª–æ–≤")
                print(f"üîç [GEMINI] –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞: {response.text[:200]}")
                print(f"üîç [GEMINI] –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini:")
                print(f"üîç [GEMINI] {response.text}")
                logger.info("Received response from Gemini")
                return response.text
            else:
                print(f"‚ùå [GEMINI] –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini")
                logger.error("Empty response from Gemini")
                return ""
                
        except Exception as e:
            print(f"‚ùå [GEMINI] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –∑–∞–ø—Ä–æ—Å–∞ –≤ Gemini: {e}")
            logger.error(f"Error sending request to Gemini: {e}")
            return ""
    
    def _create_preview_file(self, file_bytes: bytes, replacements: List[Dict[str, str]]) -> bytes:
        """
        Create preview file with red markers for user fields.
        
        Args:
            file_bytes: Original document bytes
            replacements: List of field replacements from Gemini
            
        Returns:
            Modified document bytes with red markers
        """
        try:
            print(f"üîß [PREVIEW] –°–æ–∑–¥–∞—é —Ñ–∞–π–ª –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞...")
            
            # Create BytesIO object from input bytes
            doc_stream = BytesIO(file_bytes)
            
            # Load document using python-docx
            doc = Document(doc_stream)
            
            # Create replacement mapping for preview with unique keys
            preview_replacements = {}
            field_counters = {'PARTY_2_NAME': 0, 'PARTY_2_REQUISITES': 0, 'PARTY_2_DIRECTOR_NAME': 0}
            print(f"üîç [PREVIEW] –ü–æ–ª—É—á–µ–Ω–æ {len(replacements)} –∑–∞–º–µ–Ω –æ—Ç Gemini:")
            for i, replacement in enumerate(replacements):
                print(f"üîç [PREVIEW] –ó–∞–º–µ–Ω–∞ {i+1}: type='{replacement['type']}', text='{replacement['original_text'][:50]}...'")
            
            for replacement in replacements:
                original_text = replacement['original_text']
                field_type = replacement['type']
                
                print(f"üîç [PREVIEW] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–º–µ–Ω—É: type='{field_type}', text='{original_text[:50]}...'")
                
                if field_type == 'PARTY_2_NAME':
                    field_counters['PARTY_2_NAME'] += 1
                    unique_key = f"{original_text}_{field_counters['PARTY_2_NAME']}"
                    preview_replacements[unique_key] = {
                        'original_text': original_text,
                        'replacement': '[–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞]'
                    }
                    print(f"‚úÖ [PREVIEW] –°–æ–∑–¥–∞–Ω–∞ –∑–∞–º–µ–Ω–∞ PARTY_2_NAME: '{original_text[:30]}...' -> '[–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞]'")
                elif field_type == 'PARTY_2_REQUISITES':
                    field_counters['PARTY_2_REQUISITES'] += 1
                    # –î–ª—è —Ä–µ–∫–≤–∏–∑–∏—Ç–æ–≤ –∑–∞–º–µ–Ω—è–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É –±–ª–æ–∫–∞ –æ—Ç–¥–µ–ª—å–Ω–æ,
                    # —á—Ç–æ–±—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –ø–æ–ø–∞—Å—Ç—å –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
                    lines = [l for l in original_text.split('\n') if l.strip()]
                    for i, ln in enumerate(lines):
                        unique_key = f"{ln}_{field_counters['PARTY_2_REQUISITES']}_{i}"
                        preview_replacements[unique_key] = {
                            'original_text': ln,
                            'replacement': '[–†–µ–∫–≤–∏–∑–∏—Ç—ã –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞]'
                        }
                        print(f"‚úÖ [PREVIEW] –°–æ–∑–¥–∞–Ω–∞ –∑–∞–º–µ–Ω–∞ PARTY_2_REQUISITES: '{ln[:30]}...' -> '[–†–µ–∫–≤–∏–∑–∏—Ç—ã –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞]'")
                elif field_type == 'PARTY_2_DIRECTOR_NAME':
                    field_counters['PARTY_2_DIRECTOR_NAME'] += 1
                    unique_key = f"{original_text}_{field_counters['PARTY_2_DIRECTOR_NAME']}"
                    preview_replacements[unique_key] = {
                        'original_text': original_text,
                        'replacement': '[–ò–º—è –î–∏—Ä–µ–∫—Ç–æ—Ä–∞]'
                    }
                    print(f"‚úÖ [PREVIEW] –°–æ–∑–¥–∞–Ω–∞ –∑–∞–º–µ–Ω–∞ PARTY_2_DIRECTOR_NAME: '{original_text[:30]}...' -> '[–ò–º—è –î–∏—Ä–µ–∫—Ç–æ—Ä–∞]'")
                else:
                    print(f"‚ö†Ô∏è [PREVIEW] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –ø–æ–ª—è: '{field_type}'")
            
            print(f"‚úÖ [PREVIEW] –°–æ–∑–¥–∞–Ω–æ {len(preview_replacements)} –∑–∞–º–µ–Ω –¥–ª—è –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞")
            
            # Apply replacements to document with order preservation
            self._apply_replacements_to_document_ordered(doc, preview_replacements, is_preview=True)
            
            # Save modified document to memory
            output_stream = BytesIO()
            doc.save(output_stream)
            output_bytes = output_stream.getvalue()
            
            print(f"‚úÖ [PREVIEW] –§–∞–π–ª –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–æ–∑–¥–∞–Ω: {len(output_bytes)} –±–∞–π—Ç")
            logger.info(f"Preview file created successfully. Output size: {len(output_bytes)} bytes")
            return output_bytes
            
        except Exception as e:
            print(f"‚ùå [PREVIEW] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞ –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞: {e}")
            logger.error(f"Error creating preview file: {e}")
            return b''
    
    def _create_smart_template(self, file_bytes: bytes, replacements: List[Dict[str, str]]) -> bytes:
        """
        Create smart template with standardized placeholders.
        
        Args:
            file_bytes: Original document bytes
            replacements: List of field replacements from Gemini
            
        Returns:
            Modified document bytes with smart placeholders
        """
        try:
            print(f"üîß [SMART] –°–æ–∑–¥–∞—é —É–º–Ω—ã–π —à–∞–±–ª–æ–Ω...")
            print(f"üîç [SMART] –ü–æ–ª—É—á–µ–Ω–æ {len(replacements)} –∑–∞–º–µ–Ω –æ—Ç Gemini:")
            for i, replacement in enumerate(replacements):
                print(f"üîç [SMART] –ó–∞–º–µ–Ω–∞ {i+1}: type='{replacement['type']}', text='{replacement['original_text'][:50]}...'")
            
            # Create BytesIO object from input bytes
            doc_stream = BytesIO(file_bytes)
            
            # Load document using python-docx
            doc = Document(doc_stream)
            
            # Create replacement mapping for smart template
            smart_replacements = {}
            field_counters = {'PARTY_2_NAME': 0, 'PARTY_2_REQUISITES': 0, 'PARTY_2_DIRECTOR_NAME': 0}
            
            for replacement in replacements:
                original_text = replacement['original_text']
                field_type = replacement['type']
                
                print(f"üîç [SMART] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–º–µ–Ω—É: type='{field_type}', text='{original_text[:50]}...'")
                
                if field_type == 'PARTY_2_NAME':
                    field_counters['PARTY_2_NAME'] += 1
                    # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–º–µ–Ω—ã
                    unique_key = f"{original_text}_{field_counters['PARTY_2_NAME']}"
                    smart_replacements[unique_key] = {
                        'original_text': original_text,
                        'replacement': '{{PARTY_2_NAME}}'
                    }
                    print(f"‚úÖ [SMART] –°–æ–∑–¥–∞–Ω–∞ –∑–∞–º–µ–Ω–∞ PARTY_2_NAME: '{original_text[:30]}...' -> '{{PARTY_2_NAME}}'")
                elif field_type == 'PARTY_2_REQUISITES':
                    field_counters['PARTY_2_REQUISITES'] += 1
                    # –î–ª—è —Ä–µ–∫–≤–∏–∑–∏—Ç–æ–≤ –∑–∞–º–µ–Ω—è–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É –±–ª–æ–∫–∞ –æ—Ç–¥–µ–ª—å–Ω–æ –Ω–∞ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä —Ä–µ–∫–≤–∏–∑–∏—Ç–æ–≤
                    lines = [l for l in original_text.split('\n') if l.strip()]
                    for i, ln in enumerate(lines):
                        unique_key = f"{ln}_{field_counters['PARTY_2_REQUISITES']}_{i}"
                        smart_replacements[unique_key] = {
                            'original_text': ln,
                            'replacement': '{{PARTY_2_REQUISITES}}'
                        }
                        print(f"‚úÖ [SMART] –°–æ–∑–¥–∞–Ω–∞ –∑–∞–º–µ–Ω–∞ PARTY_2_REQUISITES: '{ln[:30]}...' -> '{{PARTY_2_REQUISITES}}'")
                elif field_type == 'PARTY_2_DIRECTOR_NAME':
                    field_counters['PARTY_2_DIRECTOR_NAME'] += 1
                    # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–º–µ–Ω—ã
                    unique_key = f"{original_text}_{field_counters['PARTY_2_DIRECTOR_NAME']}"
                    smart_replacements[unique_key] = {
                        'original_text': original_text,
                        'replacement': '{{PARTY_2_DIRECTOR_NAME}}'
                    }
                    print(f"‚úÖ [SMART] –°–æ–∑–¥–∞–Ω–∞ –∑–∞–º–µ–Ω–∞ PARTY_2_DIRECTOR_NAME: '{original_text[:30]}...' -> '{{PARTY_2_DIRECTOR_NAME}}'")
                else:
                    print(f"‚ö†Ô∏è [SMART] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –ø–æ–ª—è: '{field_type}'")
            
            print(f"‚úÖ [SMART] –°–æ–∑–¥–∞–Ω–æ {len(smart_replacements)} –∑–∞–º–µ–Ω –¥–ª—è —É–º–Ω–æ–≥–æ —à–∞–±–ª–æ–Ω–∞")
            print(f"üîç [SMART] –ò—Ç–æ–≥–æ–≤—ã–µ –∑–∞–º–µ–Ω—ã:")
            for original, replacement in smart_replacements.items():
                print(f"üîç [SMART] '{original[:30]}...' -> '{replacement}'")
            
            # Apply replacements to document with order preservation
            self._apply_replacements_to_document_ordered(doc, smart_replacements, is_preview=False)
            
            # Save modified document to memory
            output_stream = BytesIO()
            doc.save(output_stream)
            output_bytes = output_stream.getvalue()
            
            print(f"‚úÖ [SMART] –£–º–Ω—ã–π —à–∞–±–ª–æ–Ω —Å–æ–∑–¥–∞–Ω: {len(output_bytes)} –±–∞–π—Ç")
            logger.info(f"Smart template created successfully. Output size: {len(output_bytes)} bytes")
            return output_bytes
            
        except Exception as e:
            print(f"‚ùå [SMART] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —É–º–Ω–æ–≥–æ —à–∞–±–ª–æ–Ω–∞: {e}")
            logger.error(f"Error creating smart template: {e}")
            return b''
    
    def _apply_replacements_to_document(self, doc: Document, replacements: Dict[str, str], is_preview: bool = True):
        """
        Apply replacements to document while preserving formatting.
        
        Args:
            doc: python-docx Document object
            replacements: Dictionary mapping original text to replacement text
            is_preview: Whether this is for preview (red formatting) or smart template
        """
        try:
            print(f"üîß [APPLY] –ü—Ä–∏–º–µ–Ω—è—é {len(replacements)} –∑–∞–º–µ–Ω –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É...")
            
            # Process all paragraphs
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    self._apply_replacements_to_paragraph(paragraph, replacements, is_preview)
            
            # Process all tables
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        for paragraph in cell.paragraphs:
                            if paragraph.text.strip():
                                self._apply_replacements_to_paragraph(paragraph, replacements, is_preview)
            
            print(f"‚úÖ [APPLY] –ó–∞–º–µ–Ω—ã –ø—Ä–∏–º–µ–Ω–µ–Ω—ã –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É")
            
        except Exception as e:
            print(f"‚ùå [APPLY] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –∑–∞–º–µ–Ω: {e}")
            logger.error(f"Error applying replacements to document: {e}")
    
    def _apply_replacements_to_document_ordered(self, doc: Document, smart_replacements: Dict[str, Dict], is_preview: bool = True):
        """
        Apply replacements to document with order preservation for identical text.
        
        Args:
            doc: python-docx Document object
            smart_replacements: Dictionary with unique keys and replacement data
            is_preview: Whether this is for preview (red formatting) or smart template
        """
        try:
            print(f"üîß [APPLY] –ü—Ä–∏–º–µ–Ω—è—é {len(smart_replacements)} –∑–∞–º–µ–Ω –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–æ—Ä—è–¥–∫–∞...")
            
            # Convert to list of replacements with order
            replacements_list = []
            for key, data in smart_replacements.items():
                replacements_list.append({
                    'original_text': data['original_text'],
                    'replacement': data['replacement']
                })
            
            # Process all paragraphs
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    self._apply_replacements_to_paragraph_ordered(paragraph, replacements_list, is_preview)
            
            # Process all tables
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        for paragraph in cell.paragraphs:
                            if paragraph.text.strip():
                                self._apply_replacements_to_paragraph_ordered(paragraph, replacements_list, is_preview)
            
            print(f"‚úÖ [APPLY] –ó–∞–º–µ–Ω—ã –ø—Ä–∏–º–µ–Ω–µ–Ω—ã –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–æ—Ä—è–¥–∫–∞")
            
        except Exception as e:
            print(f"‚ùå [APPLY] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –∑–∞–º–µ–Ω —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–æ—Ä—è–¥–∫–∞: {e}")
            logger.error(f"Error applying ordered replacements to document: {e}")
    
    def _apply_replacements_to_paragraph_ordered(self, paragraph, replacements_list: List[Dict], is_preview: bool = True):
        """
        Apply replacements to paragraph with order preservation.
        
        Args:
            paragraph: python-docx paragraph object
            replacements_list: List of replacement dictionaries
            is_preview: Whether this is for preview (red formatting) or smart template
        """
        try:
            original_text = paragraph.text
            
            # Apply replacements in order, but only once per occurrence
            applied_replacements = set()
            
            for replacement in replacements_list:
                original_part = replacement['original_text']
                replacement_text = replacement['replacement']
                
                if not original_part.strip():
                    continue
                
                # Check if this paragraph contains the replacement text
                if original_part in original_text:
                    # Create a unique identifier for this replacement
                    replacement_id = f"{original_part}_{original_text.find(original_part)}"
                    
                    if replacement_id not in applied_replacements:
                        # Apply the replacement
                        new_text = original_text.replace(original_part, replacement_text, 1)  # Replace only first occurrence
                        if new_text != original_text:
                            print(f"üîç [REPLACE] –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ:")
                            print(f"üîç [REPLACE] –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞: '{original_text[:50]}...'")
                            print(f"üîç [REPLACE] –ò—â–µ–º: '{original_part[:50]}...'")
                            print(f"üîç [REPLACE] –ó–∞–º–µ–Ω—è–µ–º –Ω–∞: '{replacement_text}'")
                            print(f"üîç [REPLACE] –¢–∏–ø —Ñ–∞–π–ª–∞: {'–ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä' if is_preview else '—É–º–Ω—ã–π —à–∞–±–ª–æ–Ω'}")
                            
                            # Update paragraph text
                            paragraph.text = new_text
                            original_text = new_text  # Update for next iteration
                            applied_replacements.add(replacement_id)
                            
                            print(f"‚úÖ [REPLACE] –ü—Ä–∏–º–µ–Ω–µ–Ω–∞ –∑–∞–º–µ–Ω–∞: '{original_part[:30]}...' -> '{replacement_text}'")
                            
        except Exception as e:
            print(f"‚ùå [REPLACE] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–º–µ–Ω–µ –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ: {e}")
            logger.error(f"Error applying replacement to paragraph: {e}")
    
    def _apply_replacements_to_paragraph(self, paragraph, replacements: Dict[str, str], is_preview: bool = True):
        """
        Apply replacements to paragraph while preserving formatting.
        
        Args:
            paragraph: python-docx paragraph object
            replacements: Dictionary mapping original text to replacement text
            is_preview: Whether this is for preview (red formatting) or smart template
        """
        try:
            original_text = paragraph.text
            
            # Check if this paragraph contains any replacement (—Å—Ç—Ä–æ–≥–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –¥–ª—è —Å—Ç—Ä–æ–∫ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–π)
            for original_part, replacement_text in replacements.items():
                if not original_part.strip():
                    continue
                # –î–ª—è –ª–∏–Ω–∏–π –∏–∑ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–π –∏ –ø—Ä–æ–±–µ–ª–æ–≤ —Ç—Ä–µ–±—É–µ–º —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è,
                # —á—Ç–æ–±—ã –∫–æ—Ä–æ—Ç–∫–∏–µ –ª–∏–Ω–∏–∏ (–¥–∏—Ä–µ–∫—Ç–æ—Ä) –Ω–µ –∑–∞–º–µ–Ω—è–ª–∏ –¥–ª–∏–Ω–Ω—ã–µ (—Ä–µ–∫–≤–∏–∑–∏—Ç—ã)
                is_underscore_only = bool(re.fullmatch(r"[_\s]+", original_part))
                match = (original_text == original_part) if is_underscore_only else (original_part in original_text)
                if match:
                    print(f"üîç [REPLACE] –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ:")
                    print(f"üîç [REPLACE] –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞: '{original_text[:100]}...'")
                    print(f"üîç [REPLACE] –ò—â–µ–º: '{original_part[:50]}...'")
                    print(f"üîç [REPLACE] –ó–∞–º–µ–Ω—è–µ–º –Ω–∞: '{replacement_text}'")
                    print(f"üîç [REPLACE] –¢–∏–ø —Ñ–∞–π–ª–∞: {'–ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä' if is_preview else '—É–º–Ω—ã–π —à–∞–±–ª–æ–Ω'}")
                    
                    # Clear the paragraph
                    paragraph.clear()
                    
                    # Split text around the original part
                    parts = ["", ""] if original_text == original_part else original_text.split(original_part)
                    
                    # Add text before the field
                    if parts[0]:
                        paragraph.add_run(parts[0])
                    
                    # Add replacement text with formatting
                    replacement_run = paragraph.add_run(replacement_text)
                    if is_preview:
                        # Red formatting for preview
                        replacement_run.font.color.rgb = RGBColor(255, 0, 0)  # Red color
                        replacement_run.font.bold = True
                    
                    # Add text after the field
                    if len(parts) > 1 and parts[1]:
                        paragraph.add_run(parts[1])
                    
                    print(f"‚úÖ [REPLACE] –ü—Ä–∏–º–µ–Ω–µ–Ω–∞ –∑–∞–º–µ–Ω–∞: '{original_part[:30]}...' -> '{replacement_text}'")
                    break
            
        except Exception as e:
            print(f"‚ùå [REPLACE] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –∑–∞–º–µ–Ω—ã: {e}")
            logger.error(f"Error applying replacement to paragraph: {e}")
    
    def _parse_gemini_edits_plan(self, response: str) -> List[Dict[str, str]]:
        """
        Parse JSON response from Gemini containing edits plan.

        Args:
            response: Raw response from Gemini

        Returns:
            List of edit plan dictionaries with run_id and field_name
        """
        try:
            print(f"üîç [PARSE] –ù–∞—á–∏–Ω–∞—é –ø–∞—Ä—Å–∏–Ω–≥ –ø–ª–∞–Ω–∞ –ø—Ä–∞–≤–æ–∫ –æ—Ç Gemini...")
            print(f"üîç [PARSE] –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(response)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"üîç [PARSE] –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞: {response[:200]}")
            
            # Clean the response (remove markdown formatting if present)
            cleaned_response = response.strip()
            
            # Remove markdown code blocks
            if cleaned_response.startswith('```json'):
                cleaned_response = cleaned_response[7:]
            elif cleaned_response.startswith('```'):
                cleaned_response = cleaned_response[3:]
            
            if cleaned_response.endswith('```'):
                cleaned_response = cleaned_response[:-3]
            
            cleaned_response = cleaned_response.strip()
            
            print(f"üîç [PARSE] –û—á–∏—â–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {cleaned_response[:100]}...")
            
            # Try multiple parsing strategies
            edits_plan = None
            
            # Strategy 1: Try to find JSON array in the response
            json_start = cleaned_response.find('[')
            json_end = cleaned_response.rfind(']') + 1
            
            if json_start != -1 and json_end > json_start:
                json_text = cleaned_response[json_start:json_end]
                print(f"üîç [PARSE] –ù–∞–π–¥–µ–Ω JSON –º–∞—Å—Å–∏–≤: –ø–æ–∑–∏—Ü–∏—è {json_start} - {json_end}")
                print(f"üîç [PARSE] JSON —Ç–µ–∫—Å—Ç: {json_text[:200]}...")
                try:
                    edits_plan = json.loads(json_text)
                    print(f"‚úÖ [PARSE] –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω JSON –º–∞—Å—Å–∏–≤")
                except json.JSONDecodeError as e:
                    print(f"‚ùå [PARSE] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –º–∞—Å—Å–∏–≤–∞: {e}")
                    edits_plan = None
            
            # Strategy 2: Try to parse the whole response
            if edits_plan is None:
                try:
                    edits_plan = json.loads(cleaned_response)
                    print(f"‚úÖ [PARSE] –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω –≤–µ—Å—å –æ—Ç–≤–µ—Ç")
                except json.JSONDecodeError as e:
                    print(f"‚ùå [PARSE] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")
                    edits_plan = None
            
            # Strategy 3: Try to extract JSON using regex
            if edits_plan is None:
                json_pattern = r'\[.*?\]'
                json_matches = re.findall(json_pattern, cleaned_response, re.DOTALL)
                if json_matches:
                    for json_match in json_matches:
                        try:
                            edits_plan = json.loads(json_match)
                            print(f"‚úÖ [PARSE] –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω JSON —á–µ—Ä–µ–∑ regex")
                            break
                        except json.JSONDecodeError:
                            continue
            
            if edits_plan is None:
                print(f"‚ùå [PARSE] –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞")
                logger.error("Could not parse JSON from Gemini response")
                return []

            if not isinstance(edits_plan, list):
                logger.error("Gemini response is not a list")
                print(f"‚ùå [PARSE] –û—Ç–≤–µ—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –º–∞—Å—Å–∏–≤–æ–º: {type(edits_plan)}")
                return []

            # Validate that each item has required fields
            valid_edits = []
            for i, item in enumerate(edits_plan):
                print(f"üîç [PARSE] –ü—Ä–æ–≤–µ—Ä—è—é —ç–ª–µ–º–µ–Ω—Ç {i}: {item}")
                if isinstance(item, dict) and 'run_id' in item and 'field_name' in item:
                    valid_edits.append(item)
                    print(f"‚úÖ [PARSE] –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ: {item['run_id']} -> '{item['field_name']}'")
                else:
                    print(f"‚ö†Ô∏è [PARSE] –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —ç–ª–µ–º–µ–Ω—Ç–∞: {item}")
            
            print(f"üîç [PARSE] –ò—Ç–æ–≥–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ –≤–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–∞–≤–æ–∫:")
            for i, edit in enumerate(valid_edits):
                print(f"üîç [PARSE] –ü—Ä–∞–≤–∫–∞ {i+1}: run_id='{edit['run_id']}', field_name='{edit['field_name']}'")
            
            logger.info(f"Successfully parsed {len(valid_edits)} valid edits from Gemini response")
            return valid_edits

        except json.JSONDecodeError as e:
            logger.error(f"Error parsing JSON response from Gemini: {e}")
            logger.error(f"Raw response: {response}")
            print(f"‚ùå [PARSE] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            print(f"‚ùå [PARSE] –ò—Å—Ö–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç: {response[:500]}...")
            return []
        except Exception as e:
            logger.error(f"Unexpected error parsing Gemini response: {e}")
            print(f"‚ùå [PARSE] –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            return []

    def _parse_gemini_response(self, response: str) -> List[Dict[str, str]]:
        """
        Parse JSON response from Gemini.

        Args:
            response: Raw response from Gemini

        Returns:
            List of field data dictionaries
        """
        try:
            print(f"üîç [PARSE] –ù–∞—á–∏–Ω–∞—é –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Gemini...")
            print(f"üîç [PARSE] –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(response)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"üîç [PARSE] –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞: {response[:200]}")
            
            # Clean the response (remove markdown formatting if present)
            cleaned_response = response.strip()
            
            # Remove markdown code blocks
            if cleaned_response.startswith('```json'):
                cleaned_response = cleaned_response[7:]
            elif cleaned_response.startswith('```'):
                cleaned_response = cleaned_response[3:]
            
            if cleaned_response.endswith('```'):
                cleaned_response = cleaned_response[:-3]
            
            cleaned_response = cleaned_response.strip()
            
            print(f"üîç [PARSE] –û—á–∏—â–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {cleaned_response[:100]}...")
            
            # Try multiple parsing strategies
            field_data = None
            
            # Strategy 1: Try to find JSON array in the response
            json_start = cleaned_response.find('[')
            json_end = cleaned_response.rfind(']') + 1
            
            if json_start != -1 and json_end > json_start:
                json_text = cleaned_response[json_start:json_end]
                print(f"üîç [PARSE] –ù–∞–π–¥–µ–Ω JSON –º–∞—Å—Å–∏–≤: –ø–æ–∑–∏—Ü–∏—è {json_start} - {json_end}")
                print(f"üîç [PARSE] JSON —Ç–µ–∫—Å—Ç: {json_text[:200]}...")
                try:
                    field_data = json.loads(json_text)
                    print(f"‚úÖ [PARSE] –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω JSON –º–∞—Å—Å–∏–≤")
                except json.JSONDecodeError as e:
                    print(f"‚ùå [PARSE] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –º–∞—Å—Å–∏–≤–∞: {e}")
                    field_data = None
            
            # Strategy 2: Try to parse the whole response
            if field_data is None:
                try:
                    field_data = json.loads(cleaned_response)
                    print(f"‚úÖ [PARSE] –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω –≤–µ—Å—å –æ—Ç–≤–µ—Ç")
                except json.JSONDecodeError as e:
                    print(f"‚ùå [PARSE] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")
                    field_data = None
            
            # Strategy 3: Try to extract JSON using regex
            if field_data is None:
                json_pattern = r'\[.*?\]'
                json_matches = re.findall(json_pattern, cleaned_response, re.DOTALL)
                if json_matches:
                    for json_match in json_matches:
                        try:
                            field_data = json.loads(json_match)
                            print(f"‚úÖ [PARSE] –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω JSON —á–µ—Ä–µ–∑ regex")
                            break
                        except json.JSONDecodeError:
                            continue
            
            if field_data is None:
                print(f"‚ùå [PARSE] –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞")
                logger.error("Could not parse JSON from Gemini response")
                return []

            if not isinstance(field_data, list):
                logger.error("Gemini response is not a list")
                print(f"‚ùå [PARSE] –û—Ç–≤–µ—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –º–∞—Å—Å–∏–≤–æ–º: {type(field_data)}")
                return []

            # Validate that each item has required fields
            valid_fields = []
            for i, item in enumerate(field_data):
                print(f"üîç [PARSE] –ü—Ä–æ–≤–µ—Ä—è—é —ç–ª–µ–º–µ–Ω—Ç {i}: {item}")
                if isinstance(item, dict) and 'original_text' in item and 'type' in item:
                    if item['type'] in ['PARTY_2_NAME', 'PARTY_2_REQUISITES', 'PARTY_2_DIRECTOR_NAME']:
                        valid_fields.append(item)
                        print(f"‚úÖ [PARSE] –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ: {item['type']} -> '{item['original_text'][:50]}...'")
                        print(f"üîç [PARSE] –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ–ª—è: '{item['original_text']}'")
                    else:
                        print(f"‚ö†Ô∏è [PARSE] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –ø–æ–ª—è: {item['type']}")
                else:
                    print(f"‚ö†Ô∏è [PARSE] –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –ø–æ–ª—è: {item}")
            
            print(f"üîç [PARSE] –ò—Ç–æ–≥–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ –≤–∞–ª–∏–¥–Ω—ã—Ö –ø–æ–ª–µ–π:")
            for i, field in enumerate(valid_fields):
                print(f"üîç [PARSE] –ü–æ–ª–µ {i+1}: type='{field['type']}', text='{field['original_text'][:100]}...'")
            
            logger.info(f"Successfully parsed {len(valid_fields)} valid fields from Gemini response")
            return valid_fields

        except json.JSONDecodeError as e:
            logger.error(f"Error parsing JSON response from Gemini: {e}")
            logger.error(f"Raw response: {response}")
            print(f"‚ùå [PARSE] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            print(f"‚ùå [PARSE] –ò—Å—Ö–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç: {response[:500]}...")
            return []
        except Exception as e:
            logger.error(f"Unexpected error parsing Gemini response: {e}")
            print(f"‚ùå [PARSE] –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            return []